{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file just converts the data from shards.txt and the rest of the low significance shards in the other file into a single csv file which is the one used by the rest ofthe code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "parser_f() got an unexpected keyword argument 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-93-4f6e5d83eb19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../GAIA_SDSS_substructures_next_30_cands.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: parser_f() got an unexpected keyword argument 'index'"
     ]
    }
   ],
   "source": [
    "from numpy import *\n",
    "import pandas\n",
    "\n",
    "\n",
    "params = ['vx','vy','vz','sigx','sigy','sigz','population']\n",
    "\n",
    "\n",
    "# First 20 something\n",
    "dat_old = loadtxt('../shards.txt', delimiter=',', usecols=arange(0,10))\n",
    "names_old = loadtxt('../shards.txt', delimiter=',', usecols=10,dtype='str')\n",
    "v_old = dat_old[:,0:3]\n",
    "sig_old = dat_old[:,6:9]\n",
    "pops_old = dat_old[:,9]\n",
    "\n",
    "num_cands = size(names_old)\n",
    "dat1 = zeros(shape=(num_cands,7))\n",
    "for i in range(0,num_cands):\n",
    "    dat1[i,0:3] = v_old[i,:]\n",
    "    dat1[i,3:6] = sig_old[i,:]\n",
    "    dat1[i,6] = 1.0*pops_old[i]\n",
    "    \n",
    "df_dat1 = pandas.DataFrame(dat1,columns=params)\n",
    "df_names = pandas.DataFrame(names_old,columns=['ID'])\n",
    "dat1_full = df_names.join(df_dat1)\n",
    "\n",
    "\n",
    "\n",
    "df = pandas.read_csv('../GAIA_SDSS_substructures_next_30_cands.csv')\n",
    "names = df.group_id.unique()\n",
    "\n",
    "\n",
    "num_cands = size(names)\n",
    "dat2 = zeros(shape=(num_cands,7))\n",
    "for i in range(0,num_cands):\n",
    "    Cand = df.loc[df['group_id'] == names[i]]\n",
    "    U = Cand.GalRVel\n",
    "    V = Cand.GalTVel\n",
    "    W = Cand.GalzVel\n",
    "    dat2[i,0:3] = array([mean(U),mean(V),mean(W)])\n",
    "    dat2[i,3:6] = array([std(U),std(V),std(W)])\n",
    "    dat2[i,6] = size(U)\n",
    "    \n",
    "df_dat2 = pandas.DataFrame(dat2,columns=params)\n",
    "df_names = pandas.DataFrame(names,columns=['ID'])\n",
    "dat2_full = df_names.join(df_dat2)\n",
    "\n",
    "dat_full = dat1_full.append(dat2_full,ignore_index=True)\n",
    "dat_full.to_csv('../Shards.csv',float_format='%.3f',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pandas.read_csv('../Shards.csv')\n",
    "names = df.ID\n",
    "nshards = size(names)\n",
    "velocities = zeros(shape=(nshards,3))\n",
    "dispersions = zeros(shape=(nshards,3))\n",
    "velocities[0:(nshards),0] = df.vx\n",
    "velocities[0:(nshards),1] = df.vy\n",
    "velocities[0:(nshards),2] = df.vz\n",
    "dispersions[0:(nshards),0] = df.sigx\n",
    "dispersions[0:(nshards),1] = df.sigy\n",
    "dispersions[0:(nshards),2] = df.sigz\n",
    "pops = df.population\n",
    "pops /= sum(pops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NCand29'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cand.group_id.unique()[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
